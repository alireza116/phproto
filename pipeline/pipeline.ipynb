{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy\n",
    "import textacy\n",
    "import re\n",
    "from textacy.preprocessing import remove_punctuation, replace_emojis, replace_urls\n",
    "import textacy.vsm \n",
    "from textacy.vsm import Vectorizer\n",
    "import textacy.tm\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import pandas as pd\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "import multiprocessing as mp\n",
    "import ast\n",
    "from twitteremotion.emotion_predictor import EmotionPredictor\n",
    "import preprocessor as p\n",
    "import json\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI)\n",
    "os.environ['KERAS_BACKEND'] = 'theano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"rawDAta/twitter_MekongRiver_disease_YHNov12.csv\"\n",
    "outPath = \"processedData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stops = [\"t\",\"co\",\"s\", \"t co\",\"g\",'s   t co',\"https\",\"htt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntities(tweet):\n",
    "  blob = TextBlob(tweet)\n",
    "  result = []\n",
    "  for sent in blob.sentences:\n",
    "    sent = str(sent)\n",
    "    sentence = Sentence(sent)\n",
    "    tagger.predict(sentence)\n",
    "    entities = sentence.to_dict(tag_type='ner')\n",
    "    for ent in entities[\"entities\"]:\n",
    "      result.append([ent[\"text\"],ent[\"labels\"]])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text = p.clean(text)\n",
    "  text = remove_punctuation(text)\n",
    "  text = replace_emojis(text)\n",
    "  text = replace_urls(text)\n",
    "  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "  text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''',\"\",text)\n",
    "  text = re.sub(r'[\\d-]',\"\",text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_model = EmotionPredictor(classification='ekman', setting='mc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = emot_model.predict_probabilities(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in [\"Anger\",\t\"Disgust\",\t'Fear',\t\"Joy\",\t\"Sadness\",\t\"Surprise\"]:\n",
    "  df[emotion] = predictions[emotion]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 10:17:46,251 https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt not found in cache, downloading to /var/folders/vq/gwn5ph656jxbd2spxww2bv_w0000gn/T/tmpwkf17erd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432197603/432197603 [01:52<00:00, 3838180.85B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 10:19:39,268 copying /var/folders/vq/gwn5ph656jxbd2spxww2bv_w0000gn/T/tmpwkf17erd to cache at /Users/darts/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 10:19:39,536 removing temp file /var/folders/vq/gwn5ph656jxbd2spxww2bv_w0000gn/T/tmpwkf17erd\n",
      "2020-12-14 10:19:39,565 loading file /Users/darts/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = [getEntities(text) for text in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ents\"] = ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllLocEnts = []\n",
    "for entList in df[\"ents\"]:\n",
    "  locEnts = []\n",
    "  for ent in entList:\n",
    "    entText = ent[0]\n",
    "    entLabel = ent[1][0].to_dict()\n",
    "    if entLabel[\"value\"] == \"LOC\":\n",
    "      locEnts.append(entText)\n",
    "  AllLocEnts.append(locEnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"locEnts\"] = AllLocEnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"entity\"] = df[\"locEnts\"].apply(lambda x: x[0] if len(x)>0 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "en = textacy.load_spacy_lang(\"enn\") #, disable=(\"parser\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = textacy.corpus.Corpus(lang=en, data=[i for i in df[\"clean_text\"]]) #data=texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = (doc._.to_terms_list(entities=False, as_strings=True, normalize = \"lower\") for doc in corpus) #  \n",
    "tokenized_docs = ([i for i in token_list if i not in other_stops and len(i)>2] for token_list in tokenized_docs)\n",
    "# do tf-idf\n",
    "vectorizer = Vectorizer(norm=\"l2\", apply_idf=True, max_df=0.95) # , vocabulary_terms = s, max_df=0.95, min_df=5, norm=\"l2\", apply_idf=True, \n",
    "doc_term_matrix = vectorizer.fit_transform(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = textacy.tm.TopicModel(\"nmf\", n_topics=20)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "doc_topic_matrix.shape\n",
    "topicTermsDict = {}\n",
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, top_n=20):\n",
    "    topicTermsDict[topic_idx] = list(top_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics = list(model.top_doc_topics(doc_topic_matrix=doc_topic_matrix,docs=-1,top_n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic_id\"] = [i[1][0] for i in doc_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['covid',\n",
       "  'thairath news covid',\n",
       "  'thairath',\n",
       "  'news covid',\n",
       "  'news',\n",
       "  'justice services',\n",
       "  'informational signboards',\n",
       "  'informational signboards vandalised',\n",
       "  'innovations',\n",
       "  'job',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'justice',\n",
       "  'khng',\n",
       "  'justice services need',\n",
       "  'infections',\n",
       "  'khng c',\n",
       "  'know',\n",
       "  'kong',\n",
       "  'kong philharmonic'],\n",
       " 1: ['students',\n",
       "  'test',\n",
       "  'let covid',\n",
       "  'class',\n",
       "  'undergrad',\n",
       "  'undergrad students',\n",
       "  'paperless test',\n",
       "  'paperless',\n",
       "  'innovations',\n",
       "  'education',\n",
       "  'giving',\n",
       "  'giving paperless',\n",
       "  'stop',\n",
       "  'giving paperless test',\n",
       "  'stop education',\n",
       "  'let',\n",
       "  'hello sofia ra',\n",
       "  'jobs during coronavirus',\n",
       "  'hanoi',\n",
       "  'jobs'],\n",
       " 2: ['today s',\n",
       "  'covid report',\n",
       "  'report',\n",
       "  'thailand shows',\n",
       "  'deaths',\n",
       "  'shows',\n",
       "  'cases from state',\n",
       "  'zero',\n",
       "  'zero deaths',\n",
       "  'new',\n",
       "  'coronavirus cases',\n",
       "  'state',\n",
       "  'quarantine',\n",
       "  'cases',\n",
       "  'amp',\n",
       "  'quarantine and zero',\n",
       "  'jobs during coronavirus',\n",
       "  'kong philharmonic',\n",
       "  'innovations',\n",
       "  'job'],\n",
       " 3: ['kong residents',\n",
       "  'pandemic than people',\n",
       "  'residents',\n",
       "  'residents more afraid',\n",
       "  'losing',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'hong kong residents',\n",
       "  'afraid of losing',\n",
       "  'afraid',\n",
       "  'losing their jobs',\n",
       "  'hong',\n",
       "  'people',\n",
       "  'kong',\n",
       "  'coronavirus pandemic',\n",
       "  'pandemic',\n",
       "  'coronavirus',\n",
       "  'utc',\n",
       "  'thvn hong kong',\n",
       "  'thvn hong'],\n",
       " 4: ['vit nam c',\n",
       "  'mc covid',\n",
       "  'nam c',\n",
       "  'bnh nhn',\n",
       "  'bnh',\n",
       "  'nhn',\n",
       "  'vit nam',\n",
       "  'nam',\n",
       "  'vit',\n",
       "  'ngi',\n",
       "  'nga',\n",
       "  't nga',\n",
       "  'covid',\n",
       "  'v angola',\n",
       "  'angola',\n",
       "  'nga v',\n",
       "  't nga v',\n",
       "  'thm',\n",
       "  'nga v angola',\n",
       "  'v t'],\n",
       " 5: ['imported',\n",
       "  'logs six imported',\n",
       "  'including french',\n",
       "  'including',\n",
       "  'expert',\n",
       "  'vietnam logs',\n",
       "  'french expert',\n",
       "  'including french expert',\n",
       "  'logs',\n",
       "  'coronavirus cases',\n",
       "  'cases',\n",
       "  'coronavirus',\n",
       "  'khng c',\n",
       "  'khng',\n",
       "  'justice services need',\n",
       "  'justice services',\n",
       "  'justice',\n",
       "  '| thvn hong',\n",
       "  'know',\n",
       "  'kong'],\n",
       " 6: ['don t',\n",
       "  'don',\n",
       "  'think',\n",
       "  'life',\n",
       "  'time',\n",
       "  'work',\n",
       "  'pandemic',\n",
       "  '| thvn hong',\n",
       "  'justice services',\n",
       "  'job',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'justice',\n",
       "  'khng',\n",
       "  'justice services need',\n",
       "  'informational signboards vandalised',\n",
       "  'khng c',\n",
       "  'know',\n",
       "  'kong',\n",
       "  'kong philharmonic'],\n",
       " 7: ['donate',\n",
       "  'thing',\n",
       "  'going',\n",
       "  'thing i know',\n",
       "  'chose',\n",
       "  'chose to donate',\n",
       "  'know',\n",
       "  'donate food',\n",
       "  'food to people',\n",
       "  'food',\n",
       "  'people',\n",
       "  'justice services',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'justice',\n",
       "  '| thvn hong',\n",
       "  'khng',\n",
       "  'khng c',\n",
       "  'kong',\n",
       "  'kong philharmonic'],\n",
       " 8: ['| thvn hong',\n",
       "  'khng',\n",
       "  'informational signboards vandalised',\n",
       "  'innovations',\n",
       "  'job',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'justice',\n",
       "  'justice services',\n",
       "  'justice services need',\n",
       "  'khng c',\n",
       "  'ngi',\n",
       "  'know',\n",
       "  'kong',\n",
       "  'kong philharmonic',\n",
       "  'kong philharmonic orchestra',\n",
       "  'kong residents',\n",
       "  'labs',\n",
       "  'labs fail',\n",
       "  'leaving'],\n",
       " 9: ['nha',\n",
       "  'rt tt',\n",
       "  'ht covid',\n",
       "  'c nha',\n",
       "  'rt tt ht',\n",
       "  'tt ht covid',\n",
       "  'tt ht',\n",
       "  'nha c nha',\n",
       "  'nha c',\n",
       "  'vit nam rt',\n",
       "  'nam rt',\n",
       "  'nam rt tt',\n",
       "  'nam',\n",
       "  'vit',\n",
       "  'justice services need',\n",
       "  'jobs during coronavirus',\n",
       "  'informational signboards vandalised',\n",
       "  'kong philharmonic orchestra',\n",
       "  'innovations',\n",
       "  'job'],\n",
       " 10: ['vandalised',\n",
       "  'signboards',\n",
       "  'informational signboards vandalised',\n",
       "  'vandalised in mrauk',\n",
       "  'mrauk',\n",
       "  'mrauk u',\n",
       "  'informational',\n",
       "  'twsp',\n",
       "  'u twsp',\n",
       "  'signboards vandalised',\n",
       "  'coronavirus informational signboards',\n",
       "  'coronavirus informational',\n",
       "  'informational signboards',\n",
       "  'kong',\n",
       "  'justice services need',\n",
       "  'kong philharmonic',\n",
       "  'kong philharmonic orchestra',\n",
       "  'khng c',\n",
       "  'justice',\n",
       "  'jobs during coronavirus'],\n",
       " 11: ['van ri',\n",
       "  'justice services need',\n",
       "  'chief prosecutor',\n",
       "  'van',\n",
       "  'huynh van',\n",
       "  'mr huynh',\n",
       "  'mr huynh van',\n",
       "  'services',\n",
       "  'services need',\n",
       "  'justice',\n",
       "  'justice services',\n",
       "  'huynh',\n",
       "  'tho',\n",
       "  'prosecutor',\n",
       "  'need',\n",
       "  'strengthened',\n",
       "  'chief',\n",
       "  'khng',\n",
       "  'informational signboards',\n",
       "  'khng c'],\n",
       " 12: ['army',\n",
       "  'prevent covid',\n",
       "  'nld representatives',\n",
       "  'detains',\n",
       "  'myanmar',\n",
       "  'representatives to prevent',\n",
       "  'arakan state',\n",
       "  'arakan',\n",
       "  'representatives',\n",
       "  'prevent',\n",
       "  'spreading',\n",
       "  'spreading in arakan',\n",
       "  'state',\n",
       "  'know',\n",
       "  'jobs during coronavirus',\n",
       "  'informational signboards vandalised',\n",
       "  'innovations',\n",
       "  'job',\n",
       "  'jobs',\n",
       "  'justice services'],\n",
       " 13: ['philharmonic orchestra',\n",
       "  'article',\n",
       "  'player has tested',\n",
       "  'positive',\n",
       "  'philharmonic',\n",
       "  'positive for covid',\n",
       "  'kong philharmonic orchestra',\n",
       "  'kong philharmonic',\n",
       "  'discov',\n",
       "  'orchestra',\n",
       "  'drug',\n",
       "  'drug discov',\n",
       "  'tested',\n",
       "  'article in drug',\n",
       "  'tested positive',\n",
       "  'player',\n",
       "  'hong kong philharmonic',\n",
       "  'wind player',\n",
       "  'wind',\n",
       "  'kong'],\n",
       " 14: ['thi',\n",
       "  'hello sofia',\n",
       "  'tai',\n",
       "  'ra thi',\n",
       "  'thi vn',\n",
       "  'vn covid',\n",
       "  'wan',\n",
       "  'hello sofia ra',\n",
       "  'sweetcherrymfc hello sofia',\n",
       "  'sweetcherrymfc hello',\n",
       "  'hello',\n",
       "  'ra thi vn',\n",
       "  'thi vn covid',\n",
       "  'sofia',\n",
       "  'sofia ra',\n",
       "  'sofia ra thi',\n",
       "  'tai wan',\n",
       "  'informational signboards',\n",
       "  'infected',\n",
       "  'infections'],\n",
       " 15: ['vaccine',\n",
       "  'participate',\n",
       "  'coronavirus vaccine',\n",
       "  'coronavirus vaccine beginning',\n",
       "  'vaccine beginning',\n",
       "  'trial',\n",
       "  'trial in europe',\n",
       "  'brave',\n",
       "  'human',\n",
       "  'human trial',\n",
       "  'beginning in oxf',\n",
       "  'beginning',\n",
       "  'oxf',\n",
       "  'coronavirus',\n",
       "  'jobs',\n",
       "  'know',\n",
       "  'khng c',\n",
       "  'khng',\n",
       "  'kong philharmonic',\n",
       "  'kong philharmonic orchestra'],\n",
       " 16: ['travel',\n",
       "  'travel during covid',\n",
       "  'outfits',\n",
       "  'vietnam',\n",
       "  'fav',\n",
       "  'fav travel',\n",
       "  'fav travel outfits',\n",
       "  'outfits for travel',\n",
       "  'hanoi',\n",
       "  'travel outfits',\n",
       "  'justice services',\n",
       "  'innovations',\n",
       "  'job',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'justice',\n",
       "  'kong philharmonic orchestra',\n",
       "  'kong philharmonic',\n",
       "  'labs fail',\n",
       "  'labs'],\n",
       " 17: ['| living',\n",
       "  'condoms',\n",
       "  'living',\n",
       "  'living in pattaya',\n",
       "  'thailand',\n",
       "  'pattaya thailand',\n",
       "  'pattaya',\n",
       "  'coronavirus',\n",
       "  '| thvn hong',\n",
       "  'khng',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'justice',\n",
       "  'justice services',\n",
       "  'justice services need',\n",
       "  'know',\n",
       "  'khng c',\n",
       "  'innovations',\n",
       "  'kong',\n",
       "  'kong philharmonic'],\n",
       " 18: ['coronavirus after leaving',\n",
       "  'woman',\n",
       "  'leaving',\n",
       "  'infected',\n",
       "  'days mandatory quarantine',\n",
       "  'found',\n",
       "  'mandatory',\n",
       "  'french woman',\n",
       "  'days',\n",
       "  'days mandatory',\n",
       "  'mandatory quarantine',\n",
       "  'woman was found',\n",
       "  'quarantine',\n",
       "  'coronavirus',\n",
       "  'justice services need',\n",
       "  'jobs',\n",
       "  'jobs during coronavirus',\n",
       "  'labs',\n",
       "  'justice',\n",
       "  'justice services'],\n",
       " 19: ['effects',\n",
       "  'united have announced',\n",
       "  'revenue',\n",
       "  'announced',\n",
       "  'announced a loss',\n",
       "  'annual revenue',\n",
       "  'united',\n",
       "  'm in annual',\n",
       "  'manchester',\n",
       "  'loss of m',\n",
       "  'loss',\n",
       "  'coronavirus pandemic',\n",
       "  'pandemic',\n",
       "  'coronavirus',\n",
       "  'justice',\n",
       "  'jobs during coronavirus',\n",
       "  'khng',\n",
       "  'justice services',\n",
       "  'justice services need',\n",
       "  'khng c']}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicTermsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(outPath+\"dataWithEmotionEntityTopic.csv\")\n",
    "with open(outPath+\"topicTermDict.json\",\"w\") as jsonFile:\n",
    "    jsonFile.write(json.dumps(topicTermsDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
